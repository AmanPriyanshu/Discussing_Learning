# Discussing_Learning
This repo will mostly be simple articles wherein I explore topics of ML/DL. It won't be in detail but hopefully will help me someday, feel free to contribute if you have any topics you want to discuss.

* [Generalizing](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/Generalizing_over_a_cup_of_TF.ipynb)

This case talks about Generalization its use case and how it is one of the most important problems faced by Artificial Neural Nets

* [Thinking about Perceptrons](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/Discussing_the_Perception_of_Perceptrons.ipynb)

This case is simple and talks about Linear and Logistic Regression for a single feature. I don't think this is the best optimization or the most optimal results but definitely something. If you cannot see the GitHub link because somehow .ipynb files do not load take a look at the [Colab Notebook](https://colab.research.google.com/drive/1ZZMGsR8xA2eEqUGrWgSt8EVNoSkdffUm?usp=sharing).

![Results of the Notebook](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/images/boost_results.PNG)

* [Thinking about Multi-Feature Perceptrons]()

Its not completely implemented and I have to check a lot of stuff so am not posting it here.

* [Quantized Acceleration of Neural Networks]()

Implementing Quantization to Accelerate Neural Network Learning. Once a sufficient accuracy is reached remove Quantization and cotinue.

* [Oracle-Council Method](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/The_Oracle_and_the_Council.ipynb)

This method is used when labelling the dataset is very expensive. The model itself samples from the dataset to be specifically labelled, so as to learn further. It selects which datapoints is required which would allow it to learn better.

* [Council for Weights](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/Council_for_Weights.ipynb)

Understanding how weight initialization seed affects final weights

![Affects of seed initialization](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/images/seed_affects.PNG =250x250)

* [Iterative Implementation of KNN for Regression](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/Iterative_Implementation_of_KNN.ipynb)

Implementation of KNN for regression using simple interpolation technique to further improve it. Gives better results than ANN and linear regression in some cases. At the cost of higher change for overfitting

![Comparison of I-KNN-Regression, Linear Regression](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/images/iterative_knn_regression.png)

* [Neuron Visualization for Binary Exploitation](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/NeuralNetFiring.ipynb)

Implemented One Class Unsupervised Classification to identify importance of different neuron based on the labels.

![Class - 0](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/images/class0nnv.png)

--------

* [Simple Logistic Regression](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/Logistic_Regression.ipynb)

* [Naive Bayes](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/Naive_Bayes_and_K_Means.ipynb)

* [K-Means](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/Naive_Bayes_and_K_Means.ipynb)

* [AutoEncoders](https://github.com/AmanPriyanshu/Discussing_Learning/blob/master/AutoEncoders.ipynb)
